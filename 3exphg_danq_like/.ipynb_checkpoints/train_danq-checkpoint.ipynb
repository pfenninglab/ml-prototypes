{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load(file='/home/eramamur/jemmie_3exphg_danq_input_data/X_train.npy')\n",
    "X_valid = np.load(file='/home/eramamur/jemmie_3exphg_danq_input_data/X_valid.npy')\n",
    "\n",
    "Y_train = np.load(file='/home/eramamur/jemmie_3exphg_danq_input_data/Y_train.npy')\n",
    "Y_valid = np.load(file='/home/eramamur/jemmie_3exphg_danq_input_data/Y_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: CUDA driver version is insufficient for CUDA runtime version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 975, 320)          33600     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 75, 320)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 320)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 75, 640)           1640960   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 75, 640)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 48000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 925)               44400925  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 925)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 2778      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 46,078,263\n",
      "Trainable params: 46,078,263\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(input_shape = (1000, 4),\n",
    "                    padding=\"valid\",\n",
    "                    strides=1,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_size=26,\n",
    "                    filters=320))                 \n",
    "                 \n",
    "          \n",
    "model.add(MaxPooling1D(pool_size=13, strides=13))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "      \n",
    "model.add(Bidirectional(LSTM(320, return_sequences=True)))\n",
    "          \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(input_dim=75*640, units=925))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print 'compiling model'\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "20/20 [==============================] - 1s - loss: 0.6954 - val_loss: 5.9155\n",
      "Epoch 2/60\n",
      "20/20 [==============================] - 6s - loss: 2.9344 - val_loss: 9.6533\n",
      "Epoch 3/60\n",
      "20/20 [==============================] - 1s - loss: 12.2796 - val_loss: 8.0956\n",
      "Epoch 4/60\n",
      "20/20 [==============================] - 1s - loss: 5.1682 - val_loss: 9.1189\n",
      "Epoch 5/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 6/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 7/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 8/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 9/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 10/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 11/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 12/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 13/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 14/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 15/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 16/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 17/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 18/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 19/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 20/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 21/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 22/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 23/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 24/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 25/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 26/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 27/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 28/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 29/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 30/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 31/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 32/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 33/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 34/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 35/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 36/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 37/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 38/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 39/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 40/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 41/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 42/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 43/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 44/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 45/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 46/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 47/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 48/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 49/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 50/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 51/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 52/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 53/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 54/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 55/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 56/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 57/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 58/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 59/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n",
      "Epoch 60/60\n",
      "20/20 [==============================] - 1s - loss: 4.8354 - val_loss: 9.1189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab94a71d310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=Y_train, batch_size=100, epochs=60, shuffle=True, verbose=1, validation_data = (X_valid, Y_valid), initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/eramamur/danq_60_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s\n",
      "20/20 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict_proba(X_train)\n",
    "pred_valid = model.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Validation AUC: 0.507936507937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print \"Training AUC:\", roc_auc_score(Y_train, pred_train)\n",
    "print \"Validation AUC:\", roc_auc_score(Y_valid, pred_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
